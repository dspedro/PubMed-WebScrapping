{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WebScrapingPubMed.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Web Scraping pubmed for retrieving data related to keyword in medicine publications"
      ],
      "metadata": {
        "id": "d-P9SllhRMf5"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZXt4qz8561B"
      },
      "source": [
        "from bs4 import BeautifulSoup as bs\n",
        "import requests\n",
        "import re # regex\n",
        "\n",
        "class scrapPub:\n",
        "\tdef __init__ (self):#(self, term)\n",
        "\t\t#self.term = str(term)\n",
        "\t\tself\n",
        "\n",
        "\tdef urlHandler (self, term, n_pages): # a very simple html generator and request based on term for search and n# of pages\n",
        "\t\tURL = \"https://pubmed.ncbi.nlm.nih.gov/?term=\"+str(term)\n",
        "\t\tif n_pages != 0:\n",
        "\t\t\tURL = URL + \"+&page=\" + str(n_pages)\n",
        "\t\tpage = requests.get(URL)\n",
        "\t\treturn page\n",
        "\n",
        "\tdef getPageNumbers (self, term): # by default the numeber of result per page is 10\n",
        "\t\tnpages = 0 # we'll need to fin the total of articles found in search\n",
        "\t\tpage = self.urlHandler(term, npages)\n",
        "\t\tsoup = bs(page.text, 'lxml')\n",
        "\t\tresults = soup.find_all('div', class_ = 'results-amount')\n",
        "\t\tif len(results) > 0:\n",
        "\t\t\tn = results[0].text.strip() \n",
        "\t\t\tn = n.replace(',','')\n",
        "\t\t\tn = re.findall(r'\\d+', n)\n",
        "\t\t\treturn int(int(n[0])/10) # the total amout of articles diveded by ten wil result the amout of pages to scrap all itens\n",
        "\t\telse: return 0\n",
        "\n",
        "\tdef getArticlesNames (self, term, npages = \"m\"):\n",
        "\t\tif npages == \"m\":\n",
        "\t\t\tnpages = self.getPageNumbers(term)\n",
        "\t\telse: \n",
        "\t\t\tnpages = int(npages)+1\n",
        "\t\tname_list=[]\n",
        "\t\t#print(npages)\n",
        "\t\tfor i in range(1, npages): # in this case it'll get the 2 fisrt pages of search, however we could go range(1, npages) for all articles\n",
        "\t\t\tpage = self.urlHandler(term, i)\n",
        "\t\t\tsoup = bs(page.text, 'lxml')\n",
        "\t\t\tarticles_tags = soup.find_all('a', class_='docsum-title')\n",
        "\t\t\tfor articles in articles_tags:\n",
        "\t\t\t\tname_list.append(articles.text.strip())\n",
        "\t\treturn name_list\n",
        "\n",
        "\tdef getAuthors(self, term, npages = \"m\"):\n",
        "\t\tif npages == \"m\":\n",
        "\t\t\tnpages = self.getPageNumbers(term)\n",
        "\t\telse: \n",
        "\t\t\tnpages = int(npages)+1\n",
        "\t\tname_list=[]\n",
        "\t\t#print(npages)\n",
        "\t\tfor i in range(1, npages): # in this case it'll get the 2 fisrt pages of search, however we could go range(1, npages) for all articles\n",
        "\t\t\tpage = self.urlHandler(term, i)\n",
        "\t\t\tsoup = bs(page.text, 'lxml')\n",
        "\t\t\tauthor_tags = soup.find_all('span', class_='docsum-authors full-authors')\n",
        "\t\t\tfor author in author_tags:\n",
        "\t\t\t\tname_list.append(author.text.strip())\n",
        "\t\treturn name_list\n",
        "\t\t\n",
        "\t\t\t\t\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyoGqNBaBu_j"
      },
      "source": [
        "Driver for titles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-6Bk8CQ9Z1r",
        "outputId": "c4bd1cf8-134d-410c-889f-36da89210785"
      },
      "source": [
        "t = str(input('write term to searh: '))\n",
        "p = str(input('write maximum pages to search or \"m\" to as much as possibel: '))\n",
        "search = scrapPub()\n",
        "print('number of pages for ' + t + ' : ',search.getPageNumbers(t))\n",
        "art = search.getArticlesNames(t,p)\n",
        "print('number of articles scraped: ',len(art))\n",
        "a = input(\"press 'a' to show the article's titles, or any to quit: \")\n",
        "if a == 'a':\n",
        "\tprint(art)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "write term to searh: dengue\n",
            "write maximum pages to search or \"m\" to as much as possibel: 2\n",
            "number of pages for dengue :  2615\n",
            "number of articles scraped:  20\n",
            "press 'a' to show the article's titles, or any to quit: a\n",
            "['Dengue.', 'Dengue Fever: Causes, Complications, and Vaccine Strategies.', 'Dengue and dengue hemorrhagic fever.', 'Dengue in children.', '[Dengue Fever].', 'The pathogenesis of dengue.', 'Dengue infection and advances in dengue vaccines for children.', 'History, epidemiology and diagnostics of dengue in the American and Brazilian contexts: a review.', 'Dengue in the elderly: a review.', 'Disease and economic burdens of dengue.', 'Liver involvement in dengue viral infections.', '[Autochthonous dengue].', 'Global spread of dengue virus types: mapping the 70 year history.', 'The global economic burden of dengue: a systematic analysis.', 'Dengue Fever: A Worldwide Threat An Overview of the Infection Process, Environmental Factors for a Global Outbreak, Diagnostic Platforms and Vaccine Developments.', \"NS1, Dengue's Dagger.\", 'Dengue.', 'Dengue in India.', 'Dengue.', 'Dengue-associated Eye Disease.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q81hXgx_BzuO"
      },
      "source": [
        "Driver for authors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJt7XWzUBuNI",
        "outputId": "34f2d560-d32b-4a30-d891-5f5fb62cfc0b"
      },
      "source": [
        "t = str(input('write term to searh: '))\n",
        "p = str(input('write maximum pages to search or \"m\" to as much as possibel: '))\n",
        "search = scrapPub()\n",
        "print('number of pages for ' + t + ' : ',search.getPageNumbers(t))\n",
        "art = search.getAuthors(t,p)\n",
        "print('number of articles scraped: ',len(art))\n",
        "a = input(\"press 'a' to show the author's names, or any to quit: \")\n",
        "if a == 'a':\n",
        "\tprint(art)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "write term to searh: dengue\n",
            "write maximum pages to search or \"m\" to as much as possibel: 2\n",
            "number of pages for dengue :  2615\n",
            "number of articles scraped:  20\n",
            "press 'a' to show the author's names, or any to quit: a\n",
            "['Guzman MG, Harris E.', 'Khetarpal N, Khanna I.', 'Gubler DJ.', 'Verhagen LM, de Groot R.', 'Moi ML, Takasaki T.', 'Whitehorn J, Simmons CP.', 'Halstead SB, Dans LF.', 'Salles TS, da Encarnação Sá-Guimarães T, de Alvarenga ESL, Guimarães-Ribeiro V, de Meneses MDF, de Castro-Salles PF, Dos Santos CR, do Amaral Melo AC, Soares MR, Ferreira DF, Moreira MF.', 'Lin RJ, Lee TH, Leo YS.', 'Castro MC, Wilson ME, Bloom DE.', 'Dissanayake HA, Seneviratne SL.', 'Sorge F, Minodier P, Velayudhan-Deschamps N.', 'Messina JP, Brady OJ, Scott TW, Zou C, Pigott DM, Duda KA, Bhatt S, Katzelnick L, Howes RE, Battle KE, Simmons CP, Hay SI.', 'Shepard DS, Undurraga EA, Halasa YA, Stanaway JD.', 'Hosseini S, Oliva-Ramírez J, Vázquez-Villegas P, Rodriguez-Garcia A, Muñoz-Soto RB, Aghamohammadi N, Martinez-Chapa SO.', 'Halstead SB, Russell PK, Brandt WE.', 'Whitehorn J, Farrar J.', 'Gupta N, Srivastava S, Jain A, Chaturvedi UC.', 'Halstead SB.', 'Latif N, Mageshan K, Biswas J, Majumder PD.']\n"
          ]
        }
      ]
    }
  ]
}